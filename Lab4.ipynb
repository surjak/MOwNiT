{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody obliczeniowe w nauce i technice\n",
    "## Laboratorium 4\n",
    "### Singular Value Decomposition\n",
    "#### Mateusz Surjak "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "Przygotuj duży (> 1000 elementów) zbiór dokumentów tekstowych w języku angielskim (np. wybrany korpus tekstów, podzbiór artykułów Wikipedii, zbiór dokumentów HTML uzyskanych za pomocą Web crawlera, zbiór rozdziałów wyciętych z\n",
    "różnych książek)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\surja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from essential_generators import DocumentGenerator\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator ktorym posłużyłem się przy generowaniu dokumentów, można odkomentować linię **'for j in range(1, 10):'** w celu wygenerowania większych plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "    \"\"\"\n",
    "    Data generator\n",
    "    \"\"\"\n",
    "    gen = DocumentGenerator()\n",
    "    for i in range(1, 1101):\n",
    "        with io.open(f\"sample_text/text_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            # for j in range(1, 10):\n",
    "            p = gen.paragraph()\n",
    "            f.write(p)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "Określ słownik słów kluczowych (termów) potrzebny do wyznaczenia wektorów\n",
    "cech bag-of-words (indeksacja). Przykładowo zbiorem takim może być unia wszystkich słów występujących we wszystkich tekstach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict():\n",
    "    dictionary={}\n",
    "    for i in range(1, 1101):\n",
    "        with io.open(f\"sample_text/text_{i}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "            f.close()\n",
    "            data = data.lower()\n",
    "            data = re.sub(r'[^\\w\\s]','',data)\n",
    "            data = re.sub('[0-9]','',data)\n",
    "            tokenized_words=nltk.word_tokenize(data)\n",
    "            for word in tokenized_words:\n",
    "                if word in dictionary.keys():\n",
    "                    dictionary[word]+=1\n",
    "                else:\n",
    "                    dictionary[word]=1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample_text/text_1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7f6dfac9bbf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f57895973dbe>\u001b[0m in \u001b[0;36mcreate_dict\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"sample_text/text_{i}.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_text/text_1.txt'"
     ]
    }
   ],
   "source": [
    "dictionary = create_dict()\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jak wydać w słowniku znajduje się ponad 14 tysięcy słów, może nie jest to wielka liczba ale znacznie przyspieszyła obliczenia.\n",
    "Początkowo miałem ponad 130 tysięcy i python miał problemy z przetwarzaniem takich danych dlatego zdecydowałem się na zmniejszenie zawartości plików."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3\n",
    "Dla każdego dokumentu j wyznacz wektor cech bag-of-words $d_{j}$ zawierający częstości występowania poszczególnych słów (termów) w tekście.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_vector(file):\n",
    "    vector_dict={}\n",
    "    for w in dictionary.keys():\n",
    "        vector_dict[w]=0\n",
    "    f = io.open(file,encoding=\"utf8\")\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'[^\\w\\s]','',data)\n",
    "    data = re.sub('[0-9]','',data)\n",
    "    words=nltk.word_tokenize(data)\n",
    "    for w in words:\n",
    "        vector_dict[w]+=1\n",
    "    return vector_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wektor cech będę przechowywał w postaci słownika gdyż przyspieszy to operacje odczytu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4\n",
    "Zbuduj rzadką macierz wektorów cech term-by-document matrix w której wektory cech ułożone są kolumnowo $A_{m×n}$ = $[d_{1}|d_{2}| . . . |d_{n}]$ (m jest liczbą termów w\n",
    "słowniku, a n liczbą dokumentów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_by_document_matrix():\n",
    "    files = os.listdir('sample_text/')\n",
    "    t_b_d_m = []\n",
    "    for i in range(1, 1101):\n",
    "        file_name = f'sample_text/text_{i}.txt'\n",
    "        bow_vector=bag_of_words_vector(file_name)\n",
    "        t_b_d_m.append(bow_vector)\n",
    "    return t_b_d_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_by_document_mtx = term_by_document_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teraz w **term_by_document_mtx** znajdują się wektory dla każdego dokumentu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 5\n",
    "Przetwórz wstępnie otrzymany zbiór danych mnożąc elementy bag-of-words przez\n",
    "inverse document frequency. Operacja ta pozwoli na redukcję znaczenia często występujących słów.\n",
    "$$IDF(w) = log\\frac{N}{n_{w}}$$\n",
    "gdzie $n_{w}$ jest liczbą dokumentów, w których występuje słowo w, a N jest całkowitą\n",
    "liczbą dokumentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_of_word(word):\n",
    "    c = 0\n",
    "    for i in term_by_document_mtx:\n",
    "        if i.get(word)>0:\n",
    "            c+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_IDF():\n",
    "    for word in dictionary.keys():\n",
    "        n_w = get_count_of_word(word)\n",
    "        m = math.log(len(term_by_document_mtx)/n_w)\n",
    "        for dic in term_by_document_mtx:\n",
    "            dic[word] = dic.get(word)*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_by_IDF()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz **term_by_document_mtx** została zmodyfikowana, każda jej wartość zostałą przemnożona przez IDF.\n",
    "Pozwoliło to nadać większe znaczenie slowom które występują rzadko a zmniejszyć znaczenie słów występujących w wielu testach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6\n",
    "Napisz program pozwalający na wprowadzenie zapytania (w postaci sekwencji\n",
    "słów) przekształcanego następnie do reprezentacji wektorowej q (bag-of-words).\n",
    "Program ma zwrócić k dokumentów najbardziej zbliżonych do podanego zapytania q. Użyj korelacji między wektorami jako miary podobieństwa\n",
    "$$\\cos{\\theta_{j}} = \\frac{q^{T}d_{j}}{||q|| ||d_{}j||}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(data):\n",
    "    vector_dict={}\n",
    "    for w in dictionary.keys():\n",
    "        vector_dict[w]=0\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'[^\\w\\s]','',data)\n",
    "    data = re.sub('[0-9]','',data)\n",
    "    words=nltk.word_tokenize(data)\n",
    "    for w in words:\n",
    "        if w in vector_dict:\n",
    "            vector_dict[w]+=1\n",
    "    return list(vector_dict.values())\n",
    "\n",
    "def get_closest_documents(data,k):\n",
    "    data_vect = create_vector(data)\n",
    "    holder = 0\n",
    "    index = None\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(term_by_document_mtx):\n",
    "        cos = np.matmul(np.array(data_vect).T,np.array(list(i.values())))/(np.linalg.norm(data_vect)*np.linalg.norm(list(i.values())))\n",
    "        if len(to_return)<k:\n",
    "            to_return.append((idx,cos))\n",
    "            to_return = sorted(to_return, key=lambda x: x[1])\n",
    "        else:\n",
    "            if cos > to_return[0][1] or math.isnan(to_return[0][1]):\n",
    "                to_return[0] = (idx,cos)\n",
    "                to_return = sorted(to_return, key=lambda x: x[1])\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(318, 0.08172827634973914), (702, 0.1519243455746266), (8, 0.6824081772328199)]\n",
      "______________________________________\n",
      "An old populism, that were. To language. golbery. with the implementation of classical music.. Portal climate oil deposits were formed in the. And are this definition. Or kingdoms, broadly to include certain types of. Are édith on seattle in 1941. this left an extensive. Kalahari desert river, then the world's. Though whether germans live abroad. jews are. Asia. colonialism plantations. these men, women and could not obtain identification and leave. Which winds morelos, who occupied. Most ancient including rainier beach, van asselt, rainier, and jefferson south of. Through e-mail. and 1940s..\n",
      "______________________________________\n",
      "______________________________________\n",
      "Precipitating deck and whitefish mountain resort near red lodge. Festivals, colonial lakes account for news. By aristippus other types. for example, the. Hadron and 0.14%. \n",
      " \n",
      " the world of coca-cola, featuring.\n",
      "______________________________________\n",
      "______________________________________\n",
      "And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "t = get_closest_documents(\"And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\"\n",
    "                          ,3)\n",
    "def read_file(index):\n",
    "    \"\"\"\n",
    "    Dodaje 1 bo pliki zaindeksowałem od 1 a tablica liczy się od 0 \n",
    "    \"\"\"\n",
    "    with io.open(f\"sample_text/text_{index+1}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "      \n",
    "        print(\"______________________________________\")\n",
    "        print(f.read())\n",
    "        print(\"______________________________________\")\n",
    "\n",
    "print(t)\n",
    "for (idx,cos) in t:\n",
    "    read_file(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wnioski: \n",
    "Jako dane wejsciowe zostal podany jeden z plików, dokłądnie plik 9(w tablicy wiświetla się 8 ale to przez to że jest indeksowana od 0, a ja pliki zaindeksowałem od 1).\n",
    "<br>\n",
    "<br>\n",
    "Dopasowanie do oryginalnego pliku wynosi 0,68, jest to spowodowane IDF. Gdy wyłączę IDF (zakomentuję wywołanie funkcji multiply_by_IDF()) kilka ramek wyżej to dopasowanie do orginalnego pliku będzie wynosić 1,0.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Reszta znalezionych plików moim zdaniem jest poprawna, wiele słów się pokrywa z wprowadzonym tesktem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 7\n",
    "Zastosuj normalizację wektorów cech $d_{j}$ i wektora q, tak aby miały one długość 1.\n",
    "Użyj zmodyfikowanej miary podobieństwa otrzymując\n",
    "$$ |q^{T}A| = [|\\cos{\\theta_{1}}|,|\\cos{\\theta_{2}}|,...,|\\cos{\\theta_{n}}|]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix():\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(term_by_document_mtx):\n",
    "        to_return.append(normalize([list(i.values())],norm=\"l1\"))\n",
    "    return to_return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_A = normalize_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **normalized_A** jest w tym monemcie macierzą wektorów domumentów dzie każdy wektor ma długość 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_vector(data):\n",
    "    data_vector_normalized = normalize([create_vector(data)],norm=\"l1\")\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(normalized_A):\n",
    "        cos = np.matmul(np.array(data_vector_normalized[0]).T,np.array(i[0]))/(np.linalg.norm(data_vector_normalized)*np.linalg.norm(i))\n",
    "        to_return.append((cos,idx))\n",
    "    return to_return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Powyższa funkcja zwraca wektor podobieństw danych wejściowych do kolejnych dokumentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional. \"\n",
    "def get_closest_documents_normalized(data,k):\n",
    "    cos_vector = get_cos_vector(data)\n",
    "    cos_vector = sorted(cos_vector, reverse=True)\n",
    "    return cos_vector[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6824081772328199, 8), (0.15192434557462658, 702), (0.08172827634973913, 318)]\n",
      "______________________________________\n",
      "And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\n",
      "______________________________________\n",
      "______________________________________\n",
      "Precipitating deck and whitefish mountain resort near red lodge. Festivals, colonial lakes account for news. By aristippus other types. for example, the. Hadron and 0.14%. \n",
      " \n",
      " the world of coca-cola, featuring.\n",
      "______________________________________\n",
      "______________________________________\n",
      "An old populism, that were. To language. golbery. with the implementation of classical music.. Portal climate oil deposits were formed in the. And are this definition. Or kingdoms, broadly to include certain types of. Are édith on seattle in 1941. this left an extensive. Kalahari desert river, then the world's. Though whether germans live abroad. jews are. Asia. colonialism plantations. these men, women and could not obtain identification and leave. Which winds morelos, who occupied. Most ancient including rainier beach, van asselt, rainier, and jefferson south of. Through e-mail. and 1940s..\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "cld = get_closest_documents_normalized(data,3)\n",
    "print(cld)\n",
    "for doc,i in cld:\n",
    "    read_file(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek:\n",
    "\n",
    "- Dokumenty które otrzymaliśmy są identyczne kilka ramek wyżej, ich dopasowanie też jest takie samo jak przed normalizacją."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 8\n",
    "W celu usunięcia szumu z macierzy A zastosuj SVD i low rank approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def svd_and_low_rank_approx(k):\n",
    "    A = []\n",
    "    for a in normalized_A:\n",
    "        A.append(a[0])\n",
    "    u,s,vt = scipy.sparse.linalg.svds(np.array(A),k=k)\n",
    "    return u @ np.diag(s)@vt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Powyższa funkcja stosuje SVD i robi low_rank_approximation, zastosowałem bibliotekę scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_after_approx(data,k):\n",
    "    result = svd_and_low_rank_approx(k)\n",
    "    data_vector_normalized = normalize([create_vector(data)],norm=\"l1\")\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(result):\n",
    "        cos = np.matmul(np.array(data_vector_normalized[0]).T,np.array(i))/(np.linalg.norm(data_vector_normalized)*np.linalg.norm(i))\n",
    "        to_return.append((cos,idx))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Powyższa funkcja zwraca wektor podobieństw danych wejściowych do kolejnych dokumentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_documents_after_approx(data,k,approx_k):\n",
    "    cos_vector = get_after_approx(data,approx_k)\n",
    "    cos_vector = sorted(cos_vector, reverse=True)\n",
    "    return cos_vector[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.23319098038557473, 718), (0.23319079346987068, 636), (0.23318859510505982, 459)]\n",
      "______________________________________\n",
      "In shared moral or ethical problems that is fallible by. In contrast, by coat type, or commonly as random-bred, moggies (chiefly british), or. That follows vivid descriptions of desert is generally accepted as coming from diverse. Moravec and march 27, 1964, the massive good friday. Medical specialties 6 vols. \n",
      " \n",
      " \n",
      " \n",
      " despite its simplicity compared with classical. Of european-american old bridge. Part egyptian her arms (from a. Party strength 397 murders.) jens ludwig, director of works,\" from αρχι- (arkhi.. By cordell also faced criticism. Notaries, they alongside low german, sorbian, romany, and frisian; they are easy to. Four, having sudan. as of january 2017 the fertility rate is 1.73 children. Started in kingdom, norway.. About 50.1 religions include. Figures may of consciousness..\n",
      "______________________________________\n",
      "______________________________________\n",
      "State where plate, or at an exhibition and. A boom bonds. starting. Into russia purely astronomy rather than to study the complex and costly in. Friends or instability (cumulus fractus). when they reach the freezing point at night and so. Unknowns.) for espoused by islamists such as the tour de france. Justice beverley december 2014 the. Bridges other to newspapers by people with heart disease were 40. Nations and mid-oceanic ridge system is explicitly based upon its. And deepened djoser designed by manuel belgrano in 1812; it was not. Commercial traffic passage in. As indoor artistic disciplines. Atmosphere. specific (disambiguation) for the most visited city. Musicians such 1822. contemporary popular. Centre georges oxbow lake: a. Legal work the publisher. in small newspapers, the.\n",
      "______________________________________\n",
      "______________________________________\n",
      "Agreement for into several. Sayed darwish, separately in temperate climates where those skills are applicable.. Sick role, instructed to perform work, or to. Flow uphill. by raymond rosenthal (1984) isbn 978-0-14-139944-7 stwertka..\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "docs = get_closest_documents_after_approx(data,3,3)\n",
    "print(docs)\n",
    "for cos,idx in docs:\n",
    "    read_file(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek 1:\n",
    "Dla małych wartości **approx_k** dokumenty zwrócone przez funckję nie są zbytnio podobne do dokumentu wejściowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3192510838510946, 8), (0.2260017789480967, 508), (0.2171433751824727, 702)]\n",
      "______________________________________\n",
      "And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\n",
      "______________________________________\n",
      "______________________________________\n",
      "Are jon emotion. nonverbal communication demonstrates one of 11 festivals with. And leaders major hub for many british cities. europe's population may fall. Summit of past few decades, most trucks will be different from study with. Basis. montana's cytology and histology are concerned with diseases. Times. mexico the romance languages, derived from *þeudō, descended from. May mean pointer, does. Entertain as the theory. a scientific law is a mother tongue or a. 1980s german emperor leo imposed a fee ceiling of its participants. a very small amount. (featuring a tribe cyclopsittini) and budgerigar (tribe melopsittacini). \n",
      " \n",
      " \n",
      " parrots are seed. Has characterized significant effect. Decorate the all bilaterian animals are the most important species, together representing. Dynamically conjugate facilities for patients are often used. when driving on. With \"sports\" french-speaking social democrats, liberals..\n",
      "______________________________________\n",
      "______________________________________\n",
      "Precipitating deck and whitefish mountain resort near red lodge. Festivals, colonial lakes account for news. By aristippus other types. for example, the. Hadron and 0.14%. \n",
      " \n",
      " the world of coca-cola, featuring.\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "docs = get_closest_documents_after_approx(data,3,200)\n",
    "print(docs)\n",
    "for cos,idx in docs:\n",
    "    read_file(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek 2:\n",
    "Dla coraz większych wartości **approx_k** dokumenty coraz bardziej przepominają dokument wejściowy, dopasowanie jest bardzo dobre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 9\n",
    "Porównaj działanie programu bez usuwania szumu i z usuwaniem szumu. Dla jakiej wartości k wyniki wyszukiwania są najlepsze (subiektywnie). Zbadaj wpływ\n",
    "przekształcenia IDF na wyniki wyszukiwania.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównaj działanie programu bez usuwania szumu i z usuwaniem szumu.\n",
    "- Moim zdaniem program z usuwaniem szumu zwraca bardziej dopasowane wyniki, lecz K musi być odpowiednio duże gdyż dla małych k < 30 napewno można zneleźć lepiej dopasowane dokumenty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dla jakiej wartości k wyniki wyszukiwania są najlepsze (subiektywnie).\n",
    "- Jeśli zależy nam na dobrym wyniku to najlepiej dać większe k(approx_k w programie), lecz dla k większych niż 150 wyniki są naprawdę bardzo dobre dlatego szacuję że najlepszą wartością będzie około 170. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zbadaj wpływ przekształcenia IDF na wyniki wyszukiwania.\n",
    "- Często pojawiające się słowa w wielu dokumentach tracą swoje znaczenie na rzecz słów które pojawiają się w niewielu dokumentach. Pozwala to na lepsze dopasowanie dokumentów gdyż uniezależniamy wejściowy dokument od pospolitych słów które się często pojawiają i możemy skupić się na porównywaniu dokumentów po bardziej niszowych słowach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
