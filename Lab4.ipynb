{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\surja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from essential_generators import DocumentGenerator\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "def gen_data():\n",
    "    \"\"\"\n",
    "    Data generator\n",
    "    \"\"\"\n",
    "    gen = DocumentGenerator()\n",
    "    for i in range(1, 1101):\n",
    "        with io.open(f\"sample_text/text_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            # for j in range(1, 10):\n",
    "            p = gen.paragraph()\n",
    "            f.write(p)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict():\n",
    "    dictionary={}\n",
    "    for i in range(1, 1101):\n",
    "        with io.open(f\"sample_text/text_{i}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "            f.close()\n",
    "            data = data.lower()\n",
    "            data = re.sub(r'[^\\w\\s]','',data)\n",
    "            data = re.sub('[0-9]','',data)\n",
    "            tokenized_words=nltk.word_tokenize(data)\n",
    "            for word in tokenized_words:\n",
    "                if word in dictionary.keys():\n",
    "                    dictionary[word]+=1\n",
    "                else:\n",
    "                    dictionary[word]=1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14319"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = create_dict()\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_vector(file):\n",
    "    vector_dict={}\n",
    "    for w in dictionary.keys():\n",
    "        vector_dict[w]=0\n",
    "    f = io.open(file,encoding=\"utf8\")\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'[^\\w\\s]','',data)\n",
    "    data = re.sub('[0-9]','',data)\n",
    "    words=nltk.word_tokenize(data)\n",
    "    for w in words:\n",
    "        vector_dict[w]+=1\n",
    "    return vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_by_document_matrix():\n",
    "    files = os.listdir('sample_text/')\n",
    "    t_b_d_m = []\n",
    "    for i in range(1, 1101):\n",
    "        file_name = f'sample_text/text_{i}.txt'\n",
    "        bow_vector=bag_of_words_vector(file_name)\n",
    "        t_b_d_m.append(bow_vector)\n",
    "    return t_b_d_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_by_document_mtx = term_by_document_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_of_word(word):\n",
    "    c = 0\n",
    "    for i in term_by_document_mtx:\n",
    "        if i.get(word)>0:\n",
    "            c+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_IDF():\n",
    "    for word in dictionary.keys():\n",
    "        n_w = get_count_of_word(word)\n",
    "        m = math.log(len(term_by_document_mtx)/n_w)\n",
    "        for dic in term_by_document_mtx:\n",
    "            dic[word] = dic.get(word)*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_by_IDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(data):\n",
    "    vector_dict={}\n",
    "    for w in dictionary.keys():\n",
    "        vector_dict[w]=0\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'[^\\w\\s]','',data)\n",
    "    data = re.sub('[0-9]','',data)\n",
    "    words=nltk.word_tokenize(data)\n",
    "    for w in words:\n",
    "        if w in vector_dict:\n",
    "            vector_dict[w]+=1\n",
    "    return list(vector_dict.values())\n",
    "\n",
    "def get_closest_documents(data,k):\n",
    "    data_vect = create_vector(data)\n",
    "    holder = 0\n",
    "    index = None\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(term_by_document_mtx):\n",
    "        cos = np.matmul(np.array(data_vect).T,np.array(list(i.values())))/(np.linalg.norm(data_vect)*np.linalg.norm(list(i.values())))\n",
    "        if len(to_return)<k:\n",
    "            to_return.append((idx,cos))\n",
    "            to_return = sorted(to_return, key=lambda x: x[1])\n",
    "        else:\n",
    "            if cos > to_return[0][1] or math.isnan(to_return[0][1]):\n",
    "                to_return[0] = (idx,cos)\n",
    "                to_return = sorted(to_return, key=lambda x: x[1])\n",
    "    return to_return\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(318, 0.08172827634973914), (702, 0.1519243455746266), (8, 0.6824081772328199)]\n",
      "______________________________________\n",
      "An old populism, that were. To language. golbery. with the implementation of classical music.. Portal climate oil deposits were formed in the. And are this definition. Or kingdoms, broadly to include certain types of. Are Ă©dith on seattle in 1941. this left an extensive. Kalahari desert river, then the world's. Though whether germans live abroad. jews are. Asia. colonialism plantations. these men, women and could not obtain identification and leave. Which winds morelos, who occupied. Most ancient including rainier beach, van asselt, rainier, and jefferson south of. Through e-mail. and 1940s..\n",
      "______________________________________\n",
      "______________________________________\n",
      "Precipitating deck and whitefish mountain resort near red lodge. Festivals, colonial lakes account for news. By aristippus other types. for example, the. Hadron and 0.14%. \n",
      " \n",
      " the world of coca-cola, featuring.\n",
      "______________________________________\n",
      "______________________________________\n",
      "And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "t = get_closest_documents(\"And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\"\n",
    "                          ,3)\n",
    "def read_file(index):\n",
    "    with io.open(f\"sample_text/text_{index+1}.txt\", \"r\") as f:\n",
    "        print(\"______________________________________\")\n",
    "        print(f.read())\n",
    "        print(\"______________________________________\")\n",
    "\n",
    "print(t)\n",
    "for (idx,cos) in t:\n",
    "    read_file(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix():\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(term_by_document_mtx):\n",
    "        to_return.append(normalize([list(i.values())],norm=\"l1\"))\n",
    "    return to_return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_A = normalize_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_vector(data):\n",
    "    data_vector_normalized = normalize([create_vector(data)],norm=\"l1\")\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(normalized_A):\n",
    "        cos = np.matmul(np.array(data_vector_normalized[0]).T,np.array(i[0]))/(np.linalg.norm(data_vector_normalized)*np.linalg.norm(i))\n",
    "        to_return.append((cos,idx))\n",
    "    return to_return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional. \"\n",
    "def get_closest_documents_normalized(data,k):\n",
    "    cos_vector = get_cos_vector(data)\n",
    "    cos_vector = sorted(cos_vector, reverse=True)\n",
    "    return cos_vector[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________\n",
      "And extends industry awards, the juno awards, which were as important as the quilombo of. Was down and hemp plantations. these men.. Spaces is terrain. unlike most mammals, when cats bring. History, 1815-1970. australia (6.4 percent), saudi. Verification of savannah from the swampland, were widespread during the nonbreeding. Monarch of classroom. in 2013, the beach handball world championships. News media regional airport, bert mooney airport and the plant and animal species. Kamerun. later, basin, red lodge, and whitefish mountain resort near libby whitefish. Fever were extreme emotional.\n",
      "______________________________________\n",
      "______________________________________\n",
      "Precipitating deck and whitefish mountain resort near red lodge. Festivals, colonial lakes account for news. By aristippus other types. for example, the. Hadron and 0.14%. \n",
      " \n",
      " the world of coca-cola, featuring.\n",
      "______________________________________\n",
      "______________________________________\n",
      "An old populism, that were. To language. golbery. with the implementation of classical music.. Portal climate oil deposits were formed in the. And are this definition. Or kingdoms, broadly to include certain types of. Are Ă©dith on seattle in 1941. this left an extensive. Kalahari desert river, then the world's. Though whether germans live abroad. jews are. Asia. colonialism plantations. these men, women and could not obtain identification and leave. Which winds morelos, who occupied. Most ancient including rainier beach, van asselt, rainier, and jefferson south of. Through e-mail. and 1940s..\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "cld = get_closest_documents_normalized(data,3)\n",
    "for doc,i in cld:\n",
    "    read_file(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_and_low_rank_approx(k):\n",
    "    A = []\n",
    "    for a in normalized_A:\n",
    "        A.append(a[0])\n",
    "\n",
    "    import scipy\n",
    "    u,s,vt = scipy.sparse.linalg.svds(np.array(A),k=k)\n",
    "    return u @ np.diag(s)@vt\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = svd_and_low_rank_approx(100)\n",
    "# print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_after_approx(data,k):\n",
    "    result = svd_and_low_rank_approx(k)\n",
    "    data_vector_normalized = normalize([create_vector(data)],norm=\"l1\")\n",
    "    to_return = []\n",
    "    for idx,i in enumerate(result):\n",
    "        cos = np.matmul(np.array(data_vector_normalized[0]).T,np.array(i))/(np.linalg.norm(data_vector_normalized)*np.linalg.norm(i))\n",
    "        to_return.append((cos,idx))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_documents_after_approx(data,k,approx_k):\n",
    "    cos_vector = get_after_approx(data,approx_k)\n",
    "    cos_vector = sorted(cos_vector, reverse=True)\n",
    "    return cos_vector[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31925108385109424, 8),\n",
       " (0.22600177894809678, 508),\n",
       " (0.21714337518247243, 702)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_documents_after_approx(data,3,200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
